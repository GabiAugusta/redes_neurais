{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9720943,"sourceType":"datasetVersion","datasetId":5947527}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/gabriellacorrea/ativ-3-change-detection?scriptVersionId=239730552\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Uso de Redes Neurais Convolucionais para Detecção de Mudanças\n\nGabriella Augusta Correa\nLuísa Santos\n","metadata":{}},{"cell_type":"markdown","source":"# Importando Bibliotecas","metadata":{}},{"cell_type":"code","source":"import os\nfrom PIL import Image\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader, Dataset\nimport torch  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T18:54:47.415592Z","iopub.execute_input":"2024-11-08T18:54:47.415891Z","iopub.status.idle":"2024-11-08T18:54:57.014639Z","shell.execute_reply.started":"2024-11-08T18:54:47.415853Z","shell.execute_reply":"2024-11-08T18:54:57.013784Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# Preparando os dados","metadata":{}},{"cell_type":"code","source":"class SYSUCDSiameseDataset(Dataset):\n    def __init__(self, root_dir, transform=None):\n        self.root_dir = root_dir\n        # Filter to keep only files that end with common image extensions\n        self.time1_images = sorted([f for f in os.listdir(os.path.join(root_dir, 'time1')) if f.endswith(('.png', '.jpg', '.jpeg'))])\n        self.time2_images = sorted([f for f in os.listdir(os.path.join(root_dir, 'time2')) if f.endswith(('.png', '.jpg', '.jpeg'))])\n        self.label_images = sorted([f for f in os.listdir(os.path.join(root_dir, 'label')) if f.endswith(('.png', '.jpg', '.jpeg'))])\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.time1_images)\n\n    def __getitem__(self, idx):\n        time1_path = os.path.join(self.root_dir, 'time1', self.time1_images[idx])\n        time2_path = os.path.join(self.root_dir, 'time2', self.time2_images[idx])\n        label_path = os.path.join(self.root_dir, 'label', self.label_images[idx])\n        \n        time1_img = Image.open(time1_path).convert(\"RGB\")\n        time2_img = Image.open(time2_path).convert(\"RGB\")\n        label_img = Image.open(label_path).convert(\"L\")  # Assuming labels are grayscale\n\n        if self.transform:\n            time1_img = self.transform(time1_img)\n            time2_img = self.transform(time2_img)\n            label_img = self.transform(label_img)\n\n        return time1_img, time2_img, label_img\n\n# Define transformations\ntransform = transforms.Compose([\n    transforms.Resize((256, 256)),  # Adjust the size as needed\n    transforms.ToTensor(),\n])\n\n# Load datasets\ntrain_dir = '/kaggle/input/modified-sysu-cd/trainmod'\nval_dir = '/kaggle/input/modified-sysu-cd/valmod'\ntest_dir = '/kaggle/input/modified-sysu-cd/testmod'\n\ntrain_dataset = SYSUCDSiameseDataset(root_dir=train_dir, transform=transform)\nval_dataset = SYSUCDSiameseDataset(root_dir=val_dir, transform=transform)\ntest_dataset = SYSUCDSiameseDataset(root_dir=test_dir, transform=transform)\n\n# Create DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T19:38:42.578325Z","iopub.execute_input":"2024-11-08T19:38:42.579176Z","iopub.status.idle":"2024-11-08T19:38:42.621358Z","shell.execute_reply.started":"2024-11-08T19:38:42.579137Z","shell.execute_reply":"2024-11-08T19:38:42.620636Z"}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"# Definindo a rede","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nimport torch\n\nclass SiameseNetwork(nn.Module):\n    def __init__(self):\n        super(SiameseNetwork, self).__init__()\n        # Shared CNN for feature extraction\n        self.cnn = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2),\n            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2),\n            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2),\n            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.Upsample(scale_factor=8, mode='bilinear', align_corners=True)  # Upsampling to match input size\n        )\n        # Output layer for pixel-wise classification\n        self.classifier = nn.Conv2d(512, 1, kernel_size=1, stride=1, padding=0)  # 1-channel output for binary mask\n        self.sigmoid = nn.Sigmoid()  # Binary mask output\n\n    def forward(self, time1_img, time2_img):\n        # Extract features from both images\n        feat1 = self.cnn(time1_img)\n        feat2 = self.cnn(time2_img)\n        \n        # Compute absolute difference\n        diff = torch.abs(feat1 - feat2)\n        \n        # Apply classifier to get pixel-wise prediction\n        out = self.classifier(diff)\n        out = self.sigmoid(out)  # Use sigmoid for binary mask output\n        \n        return out\n\n# Initialize the model and move it to GPU\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = SiameseNetwork().to(device)\n\n# Use Binary Cross-Entropy Loss for pixel-wise predictions\ncriterion = nn.BCELoss()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T18:59:10.157709Z","iopub.execute_input":"2024-11-08T18:59:10.158508Z","iopub.status.idle":"2024-11-08T18:59:10.187411Z","shell.execute_reply.started":"2024-11-08T18:59:10.158465Z","shell.execute_reply":"2024-11-08T18:59:10.186591Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"# Treinando o modelo","metadata":{}},{"cell_type":"code","source":"import torch.optim as optim\nimport torch.nn as nn\n\n# Assuming model, criterion, and optimizer are defined as in previous code\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = SiameseNetwork().to(device)\ncriterion = nn.BCELoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\nnum_epochs = 50  # Define your number of epochs\n\nfor epoch in range(num_epochs):\n    # Training loop\n    model.train()\n    train_loss = 0.0\n    for time1_img, time2_img, label_img in train_loader:\n        # Move data to the same device as the model\n        time1_img, time2_img, label_img = time1_img.to(device), time2_img.to(device), label_img.to(device)\n        \n        # Forward pass\n        outputs = model(time1_img, time2_img)\n        loss = criterion(outputs, label_img.float())\n        \n        # Backward pass and optimization\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        train_loss += loss.item() * time1_img.size(0)  # Accumulate training loss for averaging\n\n    avg_train_loss = train_loss / len(train_loader.dataset)\n\n    # Validation loop\n    model.eval()\n    val_loss = 0.0\n    with torch.no_grad():\n        for time1_img, time2_img, label_img in val_loader:\n            # Move data to the same device as the model\n            time1_img, time2_img, label_img = time1_img.to(device), time2_img.to(device), label_img.to(device)\n            \n            # Forward pass\n            outputs = model(time1_img, time2_img)\n            loss = criterion(outputs, label_img.float())\n            \n            val_loss += loss.item() * time1_img.size(0)  # Accumulate validation loss for averaging\n\n    avg_val_loss = val_loss / len(val_loader.dataset)\n    \n    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Testando o modelo","metadata":{}},{"cell_type":"markdown","source":"## Definindo as funções de teste","metadata":{}},{"cell_type":"code","source":"# Evaluation function can include IoU calculation\ndef evaluate(loader, model):\n    model.eval()\n    with torch.no_grad():\n        for time1_img, time2_img, label_img in loader:\n            time1_img, time2_img, label_img = time1_img.to(device), time2_img.to(device), label_img.to(device)\n            outputs = model(time1_img, time2_img)\n            # Convert outputs and label_img to binary for IoU calculation\n            # Calculate IoU or any other metric\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T19:35:01.494999Z","iopub.execute_input":"2024-11-08T19:35:01.495633Z","iopub.status.idle":"2024-11-08T19:35:01.501075Z","shell.execute_reply.started":"2024-11-08T19:35:01.495592Z","shell.execute_reply":"2024-11-08T19:35:01.500099Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"import time\nfrom sklearn.metrics import f1_score\nimport numpy as np\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T19:35:03.391804Z","iopub.execute_input":"2024-11-08T19:35:03.392517Z","iopub.status.idle":"2024-11-08T19:35:04.087871Z","shell.execute_reply.started":"2024-11-08T19:35:03.392476Z","shell.execute_reply":"2024-11-08T19:35:04.087086Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"def evaluate_model(model, data_loader, device='cpu', threshold=0.5):\n    model.eval()\n    \n    total_latency = 0\n    all_f1_scores = []\n    all_ious = []\n\n    with torch.no_grad():\n        for time1_img, time2_img, label_img in data_loader:\n            # Move data to the specified device\n            time1_img, time2_img, label_img = time1_img.to(device), time2_img.to(device), label_img.to(device)\n            \n            # Measure latency\n            start_time = time.time()\n            outputs = model(time1_img, time2_img)\n            latency = (time.time() - start_time) * 1000  # Convert to milliseconds\n            total_latency += latency\n\n            # Binarize outputs and labels for F1 and IoU calculation\n            preds = (outputs >= threshold).float()\n            labels = (label_img >= threshold).float()\n\n            # Compute F1 Score for each batch\n            batch_f1 = f1_score(labels.cpu().numpy().flatten(), preds.cpu().numpy().flatten())\n            all_f1_scores.append(batch_f1)\n\n            # Compute IoU for each batch\n            intersection = (preds * labels).sum().item()\n            union = (preds + labels).clamp(0, 1).sum().item()\n            iou = intersection / union if union != 0 else 0\n            all_ious.append(iou)\n    \n    # Calculate average metrics\n    avg_latency = total_latency / len(data_loader)\n    avg_f1_score = np.mean(all_f1_scores)\n    avg_iou = np.mean(all_ious)\n    \n    print(f'Average Latency: {avg_latency:.2f} ms')\n    print(f'Average F1 Score: {avg_f1_score:.4f}')\n    print(f'Average IoU: {avg_iou:.4f}')\n    \n    return avg_latency, avg_f1_score, avg_iou\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T19:35:09.22369Z","iopub.execute_input":"2024-11-08T19:35:09.224552Z","iopub.status.idle":"2024-11-08T19:35:09.235073Z","shell.execute_reply.started":"2024-11-08T19:35:09.224507Z","shell.execute_reply":"2024-11-08T19:35:09.234017Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"## Testando o modelo","metadata":{}},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)\n\n# Evaluate model and print metrics\navg_latency, avg_f1_score, avg_iou = evaluate_model(model, test_loader, device=device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T19:38:48.31974Z","iopub.execute_input":"2024-11-08T19:38:48.320479Z","iopub.status.idle":"2024-11-08T19:39:57.951733Z","shell.execute_reply.started":"2024-11-08T19:38:48.320439Z","shell.execute_reply":"2024-11-08T19:39:57.950773Z"}},"outputs":[{"name":"stdout","text":"Average Latency: 1.65 ms\nAverage F1 Score: 0.5674\nAverage IoU: 0.4168\n","output_type":"stream"}],"execution_count":20}]}